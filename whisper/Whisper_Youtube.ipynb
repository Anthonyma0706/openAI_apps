{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Youtube Videos Transcription with OpenAI's Whisper**\n",
        "\n",
        "[![blog post shield](https://img.shields.io/static/v1?label=&message=Blog%20post&color=blue&style=for-the-badge&logo=openai&link=https://openai.com/blog/whisper)](https://openai.com/blog/whisper)\n",
        "[![notebook shield](https://img.shields.io/static/v1?label=&message=Notebook&color=blue&style=for-the-badge&logo=googlecolab&link=https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)](https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)\n",
        "[![repository shield](https://img.shields.io/static/v1?label=&message=Repository&color=blue&style=for-the-badge&logo=github&link=https://github.com/openai/whisper)](https://github.com/openai/whisper)\n",
        "[![paper shield](https://img.shields.io/static/v1?label=&message=Paper&color=blue&style=for-the-badge&link=https://cdn.openai.com/papers/whisper.pdf)](https://cdn.openai.com/papers/whisper.pdf)\n",
        "[![model card shield](https://img.shields.io/static/v1?label=&message=Model%20card&color=blue&style=for-the-badge&link=https://github.com/openai/whisper/blob/main/model-card.md)](https://github.com/openai/whisper/blob/main/model-card.md)\n",
        "\n",
        "Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\n",
        "\n",
        "This Notebook will guide you through the transcription of a Youtube video using Whisper. You'll be able to explore most inference parameters or use the Notebook as-is to store the transcript and video audio in your Google Drive."
      ],
      "metadata": {
        "id": "96kvih9mXkNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Check GPU type** 🕵️\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime &rarr; Change runtime type &rarr; Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QshUbLqpX7L4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74436de5-c672-4550-d5d8-1891ac6d8abc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-a82f65c3-bcb3-0502-94db-d511edfc28d2)\n",
            "Mon Apr 17 01:48:36 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IfG0E_WbRFI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e583ee-58d0-4f13-c36a-f0feae4a7ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-_jtr477s\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-_jtr477s\n",
            "  Resolved https://github.com/openai/whisper.git to commit c09a7ae299c4c34c5839a76380ae407e7d785914\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tiktoken==0.3.1\n",
            "  Downloading tiktoken-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Collecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (2.0.0+cu118)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314) (0.18.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.11.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (67.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->openai-whisper==20230314) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798038 sha256=45add398d14d8143a757b8415e4928cce98265ac56afd3e632afe888503a48fa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u7w3qjli/wheels/fe/03/29/e7919208d11b4ab32972cb448bb84a9a675d92cd52c9a48341\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: ffmpeg-python, tiktoken, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 openai-whisper-20230314 tiktoken-0.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Install libraries** 🏗️\n",
        "#@markdown This cell will take a little while to download several libraries, including Whisper.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install pytube\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "import pytube\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1zwGAsr4sIgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02d87e4-67bf-48e4-e5b9-335e71d816c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Optional:** Save data in Google Drive 💾\n",
        "#@markdown Enter a Google Drive path and run this cell if you want to store the results inside Google Drive.\n",
        "\n",
        "# Uncomment to copy generated images to drive, faster than downloading directly from colab in my experience.\n",
        "from google.colab import drive\n",
        "drive_mount_path = Path(\"/\") / \"content\" / \"drive\"\n",
        "drive.mount(str(drive_mount_path))\n",
        "drive_mount_path /= \"MyDrive\"\n",
        "#@markdown ---\n",
        "drive_path = \"whisper openAI\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change your Google Drive path.**\n",
        "\n",
        "drive_whisper_path = drive_mount_path / Path(drive_path.lstrip(\"/\"))\n",
        "drive_whisper_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Model selection** 🧠\n",
        "\n",
        "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "#@markdown | large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "Model = 'medium' #@param ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large']\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "whisper_model = whisper.load_model(Model)\n",
        "\n",
        "if Model in whisper.available_models():\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is selected.**\"\n",
        "    ))\n",
        "else:\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is no longer available.**<br /> Please select one of the following:<br /> - {'<br /> - '.join(whisper.available_models())}\"\n",
        "    ))"
      ],
      "metadata": {
        "id": "TMhrSq_GZ6kA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "bb36af3a-c9c2-45ec-aff1-027e3615b676"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [01:49<00:00, 13.9MiB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**medium model is selected.**"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Video selection** 📺\n",
        "\n",
        "#@markdown Enter the URL of the Youtube video you want to transcribe, wether you want to save the audio file in your Google Drive, and run the cell.\n",
        "\n",
        "Type = \"Google Drive\" #@param ['Youtube video or playlist', 'Google Drive']\n",
        "#@markdown ---\n",
        "#@markdown #### **Youtube video or playlist**\n",
        "URL = \"https://www.youtube.com/watch?v=TCls75M7egE\" #@param {type:\"string\"}\n",
        "store_audio = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### **Google Drive video, audio (mp4, wav), or folder containing video and/or audio files**\n",
        "video_path = \"whisper openAI/GMT20230417-004325_Recording.m4a\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    \n",
        "    try:\n",
        "        list_video_yt = [pytube.YouTube(URL)]\n",
        "    except Exception:\n",
        "        try:\n",
        "            list_video_yt = list(pytube.Playlist(URL).videos)\n",
        "        except Exception:\n",
        "            raise(RuntimeError(f\"{URL} isn't recgnized.\"))\n",
        "    \n",
        "    for video_yt in list_video_yt:\n",
        "        try:\n",
        "            video_yt.check_availability()\n",
        "            display(\n",
        "                YouTubeVideo(video_yt.video_id)\n",
        "            )\n",
        "        except pytube.exceptions.VideoUnavailable:\n",
        "            display(\n",
        "                Markdown(f\"**{URL} isn't available.**\"),\n",
        "            )\n",
        "            raise(RuntimeError(f\"{URL} isn't available.\"))\n",
        "        video_path_local = Path(\".\").resolve() / (video_yt.video_id+\".mp4\")\n",
        "        video_yt.streams.filter(\n",
        "            type=\"audio\",\n",
        "            mime_type=\"audio/mp4\",\n",
        "            abr=\"48kbps\"\n",
        "        ).first().download(\n",
        "            output_path = video_path_local.parent,\n",
        "            filename = video_path_local.name\n",
        "        )\n",
        "        if store_audio:\n",
        "            shutil.copy(video_path_local, drive_whisper_path / video_path_local.name)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "\n",
        "elif Type == \"Google Drive\":\n",
        "    # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    if video_path.is_dir():\n",
        "        for video_path_drive in video_path.glob(\"**/*\"):\n",
        "            if video_path_drive.is_file():\n",
        "                display(Markdown(f\"**{str(video_path_drive)} selected for transcription.**\"))\n",
        "            elif video_path_drive.is_dir():\n",
        "                display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "            else:\n",
        "                display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "            video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "            shutil.copy(video_path_drive, video_path_local)\n",
        "            video_path_local_list.append(video_path_local)\n",
        "    elif video_path.is_file():\n",
        "        video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "        shutil.copy(video_path, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "        display(Markdown(f\"**{str(video_path)} selected for transcription.**\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "else:\n",
        "    raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    if video_path_local.suffix == \".mp4\":\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "        result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n"
      ],
      "metadata": {
        "id": "xYLPZQX9S7tU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "fb71113a-a6da-48a3-ff36-7ca04f63efdb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**/content/drive/MyDrive/whisper openAI/GMT20230417-004325_Recording.m4a selected for transcription.**"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-X0qB9JAzMLY",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9eaf80f4-2795-48e5-b4f1-7ac031f49500"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/GMT20230417-004325_Recording.m4a"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:09.000] 我们就尝试着开始。好的。好的。\n",
            "[00:09.000 --> 00:15.000] 现在无论在美国还是在中国,这些医疗数据都比较\n",
            "[00:15.000 --> 00:20.000] 临散的分布在各个医院或者是医疗集团。\n",
            "[00:20.000 --> 00:24.000] 就你的了解,现在有没有一个比较有代表性\n",
            "[00:24.000 --> 00:29.000] 或者一个好的手段或方式能够把这些医疗数据统合起来?\n",
            "[00:29.000 --> 00:37.000] 现在基本有两种方式。主要的方式,一是一种叫联邦学习的方式。\n",
            "[00:37.000 --> 00:45.000] 它是一个能保证隐私,最大程度保证隐私的一种方式。\n",
            "[00:45.000 --> 00:50.000] 因为它的数据是不被共享,但他们是在还是在各个医院保存着。\n",
            "[00:51.000 --> 00:59.000] 然后模型是在各个医院或者说各个server的中心去运行。\n",
            "[00:59.000 --> 01:06.000] 然后模型的开发人员不会直接有这些数据的access。\n",
            "[01:06.000 --> 01:15.000] 那么最后他们的模型的一些update是靠云端的一个中心的服务器。\n",
            "[01:15.000 --> 01:23.000] 这种方式它肯定是好在数据privatecy最大的这种保留和严谨性上。\n",
            "[01:23.000 --> 01:33.000] 但是实际上它在运行很多机器学习的模型会有一些比较大的在表现上的下降。\n",
            "[01:33.000 --> 01:42.000] 所以说目前这样的模型和模式没有超级大规模的被推广起来。\n",
            "[01:42.000 --> 01:47.000] 虽然很多人已经知道或者说几年前,包括现在的很多输入法。\n",
            "[01:47.000 --> 01:57.000] 他们其实也是根据你手机上的个人的一些书习惯进行的这样的一种训练。\n",
            "[01:57.000 --> 02:01.000] 他们肯定不会把你打的所有的字去上传到他的数据库里。\n",
            "[02:01.000 --> 02:03.000] 对我们希望不是。\n",
            "[02:03.000 --> 02:10.000] 然后还有一种就是一种中心化的把所有的数据存到一个数据库。\n",
            "[02:10.000 --> 02:13.000] 那这种情况其实最大的问题就是。\n",
            "[02:13.000 --> 02:19.000] 可不可以去隐私化或者说去标识化。\n",
            "[02:19.000 --> 02:22.000] 就是也英文叫deidentification。\n",
            "[02:22.000 --> 02:28.000] 那这种情况呢其实是有很多方式去做。\n",
            "[02:28.000 --> 02:31.000] 那么比较成功的是mimic数据机。\n",
            "[02:31.000 --> 02:37.000] mimic英文叫medical information marked for intensive care。\n",
            "[02:37.000 --> 02:45.000] 就是它原来是专门为ICU重症监护的这个情景去设计的。\n",
            "[02:45.000 --> 02:48.000] 所以说他最早的release。\n",
            "[02:48.000 --> 02:53.000] 其实是最早的版本是全部是在ICU方面的数据集。\n",
            "[02:53.000 --> 02:59.000] 那么ICU方面数据集其实它好就好在有是很密集的。\n",
            "[02:59.000 --> 03:04.000] 每一个病人他每一个甚至分钟或者秒的这个阶段。\n",
            "[03:04.000 --> 03:08.000] 他都是很重要的一些time point time stamp。\n",
            "[03:08.000 --> 03:13.000] 那么其实这让他的数据虽然只在一个医院。\n",
            "[03:13.000 --> 03:17.000] 但是通过一个医院可能将近十几年的一个积累。\n",
            "[03:17.000 --> 03:22.000] 他们在Bath Israel Hospital。\n",
            "[03:22.000 --> 03:26.000] 这一个医院的一些积累其实已经够他们。\n",
            "[03:26.000 --> 03:29.000] 巴布很大的一个规模的数据集了。\n",
            "[03:29.000 --> 03:35.000] 那么其实在这个过程中最大的问题还是privacy。\n",
            "[03:35.000 --> 03:41.000] 然后很多医院他们或多或少的医师不想把这个数据公开出来。\n",
            "[03:41.000 --> 03:46.000] 怕别人去觉得你们的治疗有问题。\n",
            "[03:46.000 --> 03:48.000] 或者说让别的医院做一些文章。\n",
            "[03:48.000 --> 03:53.000] 这都是有一些比较现实的问题。\n",
            "[03:53.000 --> 03:55.000] 不光是病人的privacy。\n",
            "[03:55.000 --> 03:59.000] 医院他们也不希望自己的治疗方案。\n",
            "[03:59.000 --> 04:03.000] 或者说自己的医生自己的各种各样的决策。\n",
            "[04:03.000 --> 04:07.000] 会被大家知道就是会被批评啊这样的。\n",
            "[04:07.000 --> 04:09.000] 其实是有很多时代的问题。\n",
            "[04:09.000 --> 04:11.000] 就不光是病人的privacy。\n",
            "[04:11.000 --> 04:15.000] 但是病人的privacy这个东西确实是比较。\n",
            "[04:15.000 --> 04:19.000] 难保保留尤其是在特定的一些区域。\n",
            "[04:19.000 --> 04:22.000] 特定的一些区假如说你是有色人种。\n",
            "[04:22.000 --> 04:25.000] 在一个非常富裕的富人区。\n",
            "[04:25.000 --> 04:27.000] 然后99%都是白人。\n",
            "[04:27.000 --> 04:32.000] 然后呢你的birthday可能是一个是非常unique。\n",
            "[04:32.000 --> 04:36.000] 那其实就是大家完全可以不通过你的名字。\n",
            "[04:36.000 --> 04:38.000] 来identify你是谁。\n",
            "[04:38.000 --> 04:40.000] 只要有你的birthday。\n",
            "[04:40.000 --> 04:43.000] 好像据说有一个统计是。\n",
            "[04:43.000 --> 04:45.000] 这个到时候可以再查一下。\n",
            "[04:45.000 --> 04:48.000] 这个统计就是大概其实在一个区里。\n",
            "[04:48.000 --> 04:50.000] 或者说在一个database里面。\n",
            "[04:50.000 --> 04:57.000] 大概有20%的birthday是完全unique。\n",
            "[04:57.000 --> 05:01.000] 但是呢如果你再加上任何一个zipcode。\n",
            "[05:01.000 --> 05:04.000] 比如说first 5digit。\n",
            "[05:04.000 --> 05:07.000] 就是5位数的zipcode。\n",
            "[05:07.000 --> 05:11.000] 因为美国这边zipcode是可以从5位数一直到9位数的。\n",
            "[05:11.000 --> 05:13.000] 如果你再加上9位数的zipcode。\n",
            "[05:13.000 --> 05:16.000] 那基本上是100%的unique。\n",
            "[05:16.000 --> 05:17.000] 然后呢。\n",
            "[05:17.000 --> 05:20.000] 你在如果是用5位数的话,\n",
            "[05:20.000 --> 05:22.000] 也基本是90%以上。\n",
            "[05:22.000 --> 05:24.000] 所以说这个deidentification是很困难的。\n",
            "[05:24.000 --> 05:27.000] 那么mimic其实是在这方面。\n",
            "[05:27.000 --> 05:28.000] 做的很好。\n",
            "[05:28.000 --> 05:31.000] 至少目前我个人没有太听到。\n",
            "[05:31.000 --> 05:34.000] 大家说在讨论mimic数据集。\n",
            "[05:34.000 --> 05:37.000] 他有很多人被identify。\n",
            "[05:37.000 --> 05:40.000] 或者说很多人也不可能没有去做这样的事情。\n",
            "[05:40.000 --> 05:45.000] 但是目前来看mimic应该还是相对做的比较不错的。\n",
            "[05:45.000 --> 05:48.000] 那另一个层面就是mimic呢。\n",
            "[05:48.000 --> 05:51.000] 他是因为有几个MIT的教授。\n",
            "[05:51.000 --> 05:56.000] 包括mimic在beth israel这个医院工作的医生去推动的。\n",
            "[05:56.000 --> 05:59.000] 他们有在这个医院有各种各样的关系。\n",
            "[05:59.000 --> 06:02.000] 然后使得医院能够在高层上。\n",
            "[06:02.000 --> 06:05.000] 跟他们有一个协议吧。\n",
            "[06:05.000 --> 06:08.000] 有一个可以合作的意愿。\n",
            "[06:08.000 --> 06:11.000] 那么就像是在浪雾的医学区。\n",
            "[06:11.000 --> 06:12.000] 就挨着。\n",
            "[06:12.000 --> 06:15.000] 还有各种各样的。\n",
            "[06:19.000 --> 06:22.000] 包括波士顿最大的医院可能是。\n",
            "[06:22.000 --> 06:25.000] 他们其实都很近。\n",
            "[06:25.000 --> 06:28.000] 可能大多数也处于一个医疗系统。\n",
            "[06:28.000 --> 06:31.000] 或者说近似的医疗系统。\n",
            "[06:31.000 --> 06:34.000] 但是他们却没有一致的同意。\n",
            "[06:34.000 --> 06:37.000] 就算在波士顿这么几个医院挨着。\n",
            "[06:37.000 --> 06:40.000] 他也是没有完全推动起来。\n",
            "[06:40.000 --> 06:43.000] 所以说mimic这个数据。\n",
            "[06:43.000 --> 06:44.000] 目前还是。\n",
            "[06:44.000 --> 06:46.000] 这么多年了。\n",
            "[06:46.000 --> 06:49.000] 在学界和业界还是一个比较珍贵的。\n",
            "[06:49.000 --> 06:52.000] 医学数据级也是一个相对。\n",
            "[06:52.000 --> 06:54.000] 独一档的一个。\n",
            "[06:54.000 --> 06:57.000] 数据数据任务。\n",
            "[06:57.000 --> 06:58.000] 对。\n",
            "[06:58.000 --> 07:01.000] 大概就是这样。\n",
            "[07:01.000 --> 07:03.000] 谢谢明阳。\n",
            "[07:03.000 --> 07:06.000] 那其实刚刚明阳给我们简要的去。\n",
            "[07:06.000 --> 07:09.000] 介绍了现在已经有的。\n",
            "[07:09.000 --> 07:12.000] 代表性的手段和方式来实现数据。\n",
            "[07:12.000 --> 07:15.000] 特别是mimic这个手段。\n",
            "[07:15.000 --> 07:18.000] 那包括明阳也提到了他具体在数量。\n",
            "[07:18.000 --> 07:21.000] 这个数据管理。\n",
            "[07:21.000 --> 07:24.000] 数据质量的保证上都做的比较好。\n",
            "[07:24.000 --> 07:27.000] 那其实还想去追问明阳的是。\n",
            "[07:27.000 --> 07:30.000] 因为具体应用在我们的实际的。\n",
            "[07:30.000 --> 07:33.000] 医学研究与创新。\n",
            "[07:33.000 --> 07:36.000] 或者是在他的这个技术的演变上。\n",
            "[07:36.000 --> 07:39.000] 到底是怎么去发展的?\n",
            "[07:39.000 --> 07:42.000] 有没有一些具体的实例明样可以和我们分享。\n",
            "[07:42.000 --> 07:45.000] 对这个首先。\n",
            "[07:45.000 --> 07:48.000] 其实包括我们在一些课上去做的。\n",
            "[07:48.000 --> 07:51.000] 一些机器学习的模型,也都是去预测。\n",
            "[07:51.000 --> 07:54.000] 病人在ICU的存活率。\n",
            "[07:54.000 --> 07:57.000] 或者说他在ICU的各种各样的一些。\n",
            "[07:57.000 --> 08:00.000] 这种危险性的一个指标吧。\n",
            "[08:00.000 --> 08:02.000] 基于。\n",
            "[08:02.000 --> 08:05.000] 因为ICU里面有各种各样的仪器。\n",
            "[08:05.000 --> 08:08.000] 然后呢,我们去用这种方式去理解。\n",
            "[08:08.000 --> 08:11.000] 什么样的参数,或者什么样参数的一种组合。\n",
            "[08:11.000 --> 08:14.000] 会对这种,比如说病人的死亡。\n",
            "[08:14.000 --> 08:17.000] 还是说存活有一些很较大的影响。\n",
            "[08:17.000 --> 08:20.000] 然后他也可以提供一些预警。\n",
            "[08:20.000 --> 08:23.000] 我们当时。\n",
            "[08:23.000 --> 08:26.000] 其实他本质上如果能做出这样的一个模型,\n",
            "[08:26.000 --> 08:29.000] 那就可以去当成一个预警嘛。\n",
            "[08:29.000 --> 08:32.000] 假如说我们预测这个病人是危险性比较高。\n",
            "[08:32.000 --> 08:35.000] 可能啊,病人啊,医生和护士会。\n",
            "[08:35.000 --> 08:38.000] 更加关照一些,或者说基于这些。\n",
            "[08:38.000 --> 08:41.000] 这个这样的一些病人的这样的一些参数。\n",
            "[08:41.000 --> 08:44.000] 他有没有一些对应的治疗,这些东西。\n",
            "[08:44.000 --> 08:47.000] 都是可以在医学上推动创新的。\n",
            "[08:47.000 --> 08:50.000] 然后同时我们也必须要。\n",
            "[08:50.000 --> 08:53.000] 去学习有没有一些数据是。\n",
            "[08:53.000 --> 08:56.000] 存在Data leakage,就是叫数据泄漏。\n",
            "[08:56.000 --> 08:59.000] 这个东西其实就是我们的。\n",
            "[08:59.000 --> 09:02.000] 意思就是我们训练的一些啊。\n",
            "[09:02.000 --> 09:05.000] 一些特征。\n",
            "[09:05.000 --> 09:08.000] 他们其实是映射了。\n",
            "[09:08.000 --> 09:11.000] 我们去预测的这个。\n",
            "[09:11.000 --> 09:14.000] Label的一些信息,比如说这个病人。\n",
            "[09:14.000 --> 09:17.000] 是存活还是死亡。\n",
            "[09:17.000 --> 09:20.000] 或者说这个病人的一些指标,\n",
            "[09:20.000 --> 09:23.000] 比如说我们预测他的血氧度这样那样的。\n",
            "[09:23.000 --> 09:26.000] 很有可能其他的几个。\n",
            "[09:26.000 --> 09:29.000] 数据数据集里面这种feature。\n",
            "[09:29.000 --> 09:32.000] 特征会涵盖他们。\n",
            "[09:32.000 --> 09:35.000] 最后的那个表征最后的。\n",
            "[09:35.000 --> 09:38.000] Label的表征,所以说。\n",
            "[09:38.000 --> 09:41.000] 其实就是通过这样的一种分析。\n",
            "[09:41.000 --> 09:44.000] 我们也要去注意这样的事情。\n",
            "[09:44.000 --> 09:47.000] 然后学会怎么样在医学数据集上。\n",
            "[09:47.000 --> 09:50.000] 去进行机器学习,然后啊。\n",
            "[09:50.000 --> 09:53.000] 这也是一个很重要的东西。\n",
            "[09:53.000 --> 09:56.000] 还有一个比较好的点是他其实存。\n",
            "[09:56.000 --> 09:59.000] 他其实包含了很多种。\n",
            "[09:59.000 --> 10:02.000] 模态有time series。\n",
            "[10:02.000 --> 10:05.000] 的这样的一种数据。\n",
            "[10:05.000 --> 10:08.000] 还有图像数据,比如说胸部X光片。\n",
            "[10:08.000 --> 10:11.000] 还有CT啊。各种各样的东西。\n",
            "[10:11.000 --> 10:14.000] 其实我们都可以用啊。\n",
            "[10:14.000 --> 10:17.000] 无论是计算机视觉的啊。\n",
            "[10:17.000 --> 10:20.000] 模型还有处理病人的。\n",
            "[10:20.000 --> 10:23.000] 电子病例,我们可以去用一些自然语言。\n",
            "[10:23.000 --> 10:26.000] 处理的模型,然后跟针对于。\n",
            "[10:26.000 --> 10:29.000] 这样的数据进行一些预测。\n",
            "[10:29.000 --> 10:32.000] 和疾病的检测啊。这些东西。\n",
            "[10:32.000 --> 10:35.000] 都是比较啊。相对。\n",
            "[10:35.000 --> 10:37.000] 是是。\n",
            "[10:37.000 --> 10:40.000] 然后呢,其实。\n",
            "[10:40.000 --> 10:43.000] 最最大的一个优势其实是。\n",
            "[10:43.000 --> 10:46.000] 他的开放和获取,其实只要你做。\n",
            "[10:46.000 --> 10:49.000] 做过一个他的training,你就都可以。\n",
            "[10:49.000 --> 10:52.000] 进入Mimic的access。\n",
            "[10:52.000 --> 10:55.000] 所以。\n",
            "[10:55.000 --> 10:58.000] 并且Mimic他还包含着不同领域的信息。\n",
            "[10:58.000 --> 11:01.000] 然后包含了很多人种,很多。\n",
            "[11:01.000 --> 11:04.000] 年龄的一些分布。\n",
            "[11:04.000 --> 11:07.000] 然后。各种各样的,其实都可以去。\n",
            "[11:07.000 --> 11:09.000] 针对。\n",
            "[11:09.000 --> 11:12.000] 无论是一些人种还是说一些年龄的组。\n",
            "[11:12.000 --> 11:15.000] 进行一些细分的啊。机器学习研究。\n",
            "[11:15.000 --> 11:18.000] 和创新。对。然后。\n",
            "[11:18.000 --> 11:21.000] 相比较多的研究成果和产品,其实。\n",
            "[11:21.000 --> 11:24.000] 啊。有很多。\n",
            "[11:24.000 --> 11:27.000] 比如说。啊。是通用于感染引起的。\n",
            "[11:27.000 --> 11:30.000] 各种各样的器官功能障碍,还有败血症。\n",
            "[11:30.000 --> 11:33.000] 的一些早期检测和监测。\n",
            "[11:33.000 --> 11:36.000] 对重症护理啊。疾病的。\n",
            "[11:36.000 --> 11:39.000] 流行病的研究。比如说。一些。\n",
            "[11:39.000 --> 11:42.000] 急性肾损伤。和急性呼吸窘迫的。综合症。\n",
            "[11:42.000 --> 11:45.000] 然后。各个还有各种。\n",
            "[11:45.000 --> 11:48.000] 和。抗疫措施。有效性和安全性的研究。\n",
            "[11:48.000 --> 11:51.000] 对。大。\n",
            "[11:51.000 --> 11:54.000] 大概就是这些。好的。谢谢明杨。\n",
            "[11:54.000 --> 11:57.000] 嗯。那。其实。刚刚明杨提到了。\n",
            "[11:57.000 --> 12:00.000] 就是。他就。部分患者的。这些信息。\n",
            "[12:00.000 --> 12:03.000] 其实是。啊。是有他的创新性和独特性的。\n",
            "[12:03.000 --> 12:06.000] 那我们其实设计。这个一个新的记录系。\n",
            "[12:06.000 --> 12:09.000] 系统的时候。啊。可能考虑。\n",
            "[12:09.000 --> 12:12.000] 医院的运营。也有可能考虑。\n",
            "[12:12.000 --> 12:15.000] 嗯。这个。以患者。为中心去做一些。\n",
            "[12:15.000 --> 12:18.000] 实际的。通过医疗数据实现的。\n",
            "[12:18.000 --> 12:21.000] 服务创新。那从明杨的视角来看。\n",
            "[12:21.000 --> 12:24.000] 关于患者。\n",
            "[12:24.000 --> 12:27.000] 我们的这个数据系统呢。\n",
            "[12:27.000 --> 12:30.000] 有哪些。改善。针对。就是其他。\n",
            "[12:30.000 --> 12:33.000] 或者是我们之前的这种。医疗数据系统的。\n",
            "[12:33.000 --> 12:36.000] 这种版本来看。嗯。\n",
            "[12:36.000 --> 12:39.000] 针对于患者的话。这个是。\n",
            "[12:39.000 --> 12:42.000] 具体指。哪方面。针对于患者的。\n",
            "[12:42.000 --> 12:45.000] 呃。他可能。他直接的使用。\n",
            "[12:45.000 --> 12:48.000] 呃。他的。查看这些数据。\n",
            "[12:48.000 --> 12:51.000] 以及。设计到他自己的隐私。\n",
            "[12:51.000 --> 12:54.000] 嗯。\n",
            "[12:54.000 --> 12:57.000] 我不是很懂。这个。针对于患者。\n",
            "[12:57.000 --> 13:00.000] 这一步。还是。嗯。\n",
            "[13:00.000 --> 13:03.000] 什么意思。呃。\n",
            "[13:03.000 --> 13:06.000] 就这个系统。现在是我们医院在用。然后。\n",
            "[13:06.000 --> 13:09.000] 但是。患者是受益于。我们这个。\n",
            "[13:10.000 --> 13:13.000] 医疗数据。就我们是双向的。一部分是给医生。\n",
            "[13:13.000 --> 13:16.000] 就是。或者是数据的。这个。呃。研究者。然后一部分。\n",
            "[13:16.000 --> 13:19.000] 就是。患者。是能拿到明明的数据吗。\n",
            "[13:19.000 --> 13:22.000] 就是。其实是由他的数据。生成到。\n",
            "[13:22.000 --> 13:25.000] 这个数据系统。对不对。那他自己。\n",
            "[13:25.000 --> 13:28.000] 和这个数据。系统之间。还会有什么互动吗。\n",
            "[13:28.000 --> 13:31.000] 我觉得应该没有。因为。首先。\n",
            "[13:31.000 --> 13:34.000] 患者就算是要拿到数据。也是\n",
            "[13:34.000 --> 13:37.000] 直接从医院的渠道。去拿到。\n",
            "[13:37.000 --> 13:40.000] 而不是从。因为首先。也是。他是。\n",
            "[13:40.000 --> 13:43.000] 如果。患者能够。\n",
            "[13:43.000 --> 13:46.000] 从。里面。发现。自己。呃。除非说。他\n",
            "[13:46.000 --> 13:49.000] 看。看了所有的。电子病例。然后。发现。有一个病例。\n",
            "[13:49.000 --> 13:52.000] 跟自己。就是一模一样。那这个。他是可以查到。\n",
            "[13:52.000 --> 13:55.000] 自己可能会被。放进。但是实际上。\n",
            "[13:55.000 --> 13:58.000] 实际上。这样的意义。可能也不大。我觉得。\n",
            "[13:58.000 --> 14:01.000] 这些医院。肯定也是在。呃。\n",
            "[14:01.000 --> 14:04.000] 对这些患者。呃。有他们的这些同意。\n",
            "[14:04.000 --> 14:07.000] 然后。如果患者想要去。\n",
            "[14:07.000 --> 14:10.000] 拿到自己的病例。肯定是直接跟医院去。\n",
            "[14:10.000 --> 14:13.000] 要。或者说。他们自己也会有一些。\n",
            "[14:13.000 --> 14:16.000] 病例。那MIMIC其实跟电子病例的。\n",
            "[14:16.000 --> 14:19.000] 他其实并不是在一个渠道上。\n",
            "[14:19.000 --> 14:22.000] 因为MIMIC他就是一个集成的数据库。\n",
            "[14:22.000 --> 14:25.000] 是由MIT和一些。\n",
            "[14:25.000 --> 14:28.000] 呃。学者。包括。呃。\n",
            "[14:28.000 --> 14:31.000] Beth Israel Hospital。一些研究。创新的。\n",
            "[14:31.000 --> 14:34.000] 一些。呃。工作人员去。\n",
            "[14:34.000 --> 14:37.000] 维持的。对。他其实跟患者没有太大的\n",
            "[14:37.000 --> 14:38.000] 交集。\n",
            "[14:39.000 --> 14:42.000] 明白了。谢谢MIMIC的解释。\n",
            "[14:42.000 --> 14:45.000] 那。其实。呃。\n",
            "[14:45.000 --> 14:48.000] 就。呃。整个的这个创新而言。可能他现在\n",
            "[14:48.000 --> 14:51.000] 是由。呃。Beth Israel Hospital主要去\n",
            "[14:51.000 --> 14:54.000] 推。那现在在美国市场上。他。\n",
            "[14:54.000 --> 14:57.000] 呃。有没有在其他的。呃。无论是综合还是专科的。\n",
            "[14:57.000 --> 15:00.000] 医院去用。或者是北美区。\n",
            "[15:02.000 --> 15:05.000] 嗯。你是说。这种。数据库。数据库的\n",
            "[15:05.000 --> 15:08.000] 模式。还是说。别的医院。\n",
            "[15:08.000 --> 15:11.000] MIMIC的数据去做一些事情。\n",
            "[15:11.000 --> 15:14.000] 呃。都行。就是可能\n",
            "[15:14.000 --> 15:16.000] 从模式和。\n",
            "[15:16.000 --> 15:20.000] 这个模式的话。我目前还没太\n",
            "[15:20.000 --> 15:23.000] 听到。呃。有。但是没有Clinic。\n",
            "[15:23.000 --> 15:26.000] 是美国这个。最大的医院。可能也是排名\n",
            "[15:26.000 --> 15:30.000] 第一的医院。他们其实也是一直在推动数字化。还有。\n",
            "[15:30.000 --> 15:33.000] 对于数据的一些。\n",
            "[15:33.000 --> 15:36.000] 呃。至少是他们内部的一些。\n",
            "[15:36.000 --> 15:39.000] 呃。存储和一些研究。但是。\n",
            "[15:39.000 --> 15:42.000] 呃。他们的数据还没有被完全公开。\n",
            "[15:42.000 --> 15:45.000] 可能说你必须要进入。\n",
            "[15:45.000 --> 15:48.000] 他的医院。你才有机会去。\n",
            "[15:48.000 --> 15:51.000] 做一些。呃。工作。然后其他的\n",
            "[15:51.000 --> 15:54.000] 医院。如果需要用MIMIC的数据去进行\n",
            "[15:54.000 --> 15:57.000] 一些。啊。疾病的。\n",
            "[15:57.000 --> 16:00.000] 呃。研究。或者说。\n",
            "[16:00.000 --> 16:03.000] 进行一些机器学习模型的分析。\n",
            "[16:03.000 --> 16:06.000] 我觉得肯定是会有。啊。包括各种各样的\n",
            "[16:06.000 --> 16:09.000] 研究所。其实他们。MIMIC数据库。\n",
            "[16:09.000 --> 16:12.000] 绝对是一个。在很多领域。\n",
            "[16:12.000 --> 16:15.000] 都是一个非常宝贵的数据。就算是在。\n",
            "[16:15.000 --> 16:18.000] 计算机视觉。包括。\n",
            "[16:18.000 --> 16:21.000] 医学影像的研究。如果是。啊。\n",
            "[16:21.000 --> 16:24.000] 包括这种胸部X光片的研究。\n",
            "[16:24.000 --> 16:27.000] 那MIMIC数据。通常会被。\n",
            "[16:27.000 --> 16:30.000] 啊。就和其他的一些胸部X光片的数据库。\n",
            "[16:30.000 --> 16:33.000] 合并。然后一起去进行训练。\n",
            "[16:33.000 --> 16:36.000] 对。基本上是这样。明白了。\n",
            "[16:36.000 --> 16:39.000] 谢谢明杨。那。其实。明杨。\n",
            "[16:39.000 --> 16:42.000] 从这个医疗数据系统当中去。\n",
            "[16:42.000 --> 16:45.000] 呃。分析了他的作用。那。我们再把。\n",
            "[16:45.000 --> 16:48.000] 就是视角提到。就是明杨你就开始给我们分享。\n",
            "[16:48.000 --> 16:51.000] 联邦学习。呃。\n",
            "[16:51.000 --> 16:54.000] 就我的理解来看。他应该是把。\n",
            "[16:54.000 --> 16:57.000] 更广泛的这些数据都能够统合起来。其实现在中国。\n",
            "[16:57.000 --> 17:00.000] 也在做类似的尝试。就比如新组建的。\n",
            "[17:00.000 --> 17:03.000] 这个国家数据局。他可能在未来。\n",
            "[17:03.000 --> 17:06.000] 也会处理关于。呃。就是全国。\n",
            "[17:06.000 --> 17:09.000] 这些医疗数据相关的。问题。可能。\n",
            "[17:09.000 --> 17:12.000] 里头包括。啊。确定这些医疗数据的。\n",
            "[17:12.000 --> 17:15.000] 归属权。脱名。在利用。明杨对这个。\n",
            "[17:15.000 --> 17:18.000] 的发展。怎么看。嗯。\n",
            "[17:18.000 --> 17:21.000] 我个人对联邦学习。还是有一些。\n",
            "[17:21.000 --> 17:24.000] 期待。但是我目前还是觉得。这样的方式。\n",
            "[17:24.000 --> 17:27.000] 是比较难。呃。\n",
            "[17:27.000 --> 17:30.000] 让普通的一些。呃。\n",
            "[17:30.000 --> 17:33.000] 比如说。这种研究人员啊。\n",
            "[17:33.000 --> 17:36.000] 或者像我这样的学生。去。\n",
            "[17:36.000 --> 17:39.000] 入手的上手的。因为。首先。\n",
            "[17:39.000 --> 17:42.000] 你如果想要去用联邦学习的方式。\n",
            "[17:42.000 --> 17:45.000] 去进行一些工作。那你首先需要。\n",
            "[17:45.000 --> 17:48.000] 有他们所有医院的。\n",
            "[17:48.000 --> 17:51.000] 数据的access。然后。\n",
            "[17:51.000 --> 17:54.000] 我也知道有一些。实验室。\n",
            "[17:54.000 --> 17:57.000] 是专门研究联邦学习。\n",
            "[17:57.000 --> 18:00.000] 他们的方式。其实是也是从各个地方。\n",
            "[18:00.000 --> 18:03.000] 要到一些数据。只不过他们不把。\n",
            "[18:03.000 --> 18:06.000] 这些数据合并在一起。进行训练。他们是。\n",
            "[18:06.000 --> 18:09.000] 做了一个这种模仿的。联邦学习吧。\n",
            "[18:09.000 --> 18:12.000] 去进行这方面的一些研究。然后看。\n",
            "[18:12.000 --> 18:15.000] 呃。这些效果怎么样。\n",
            "[18:15.000 --> 18:18.000] 然后我。我目前还是觉得。\n",
            "[18:18.000 --> 18:21.000] 至少我个人最喜欢的方式。还是像mimic这样。\n",
            "[18:21.000 --> 18:24.000] 呃。我有所有的数据的access。\n",
            "[18:24.000 --> 18:27.000] 我很稳定。我不需要去每天担心很多事情。\n",
            "[18:27.000 --> 18:30.000] 但是联邦学习呢。可能是。\n",
            "[18:30.000 --> 18:33.000] 呃。如果有一种大的机构和权力。\n",
            "[18:33.000 --> 18:36.000] 比较大的话。他其实可以去。\n",
            "[18:36.000 --> 18:39.000] 去做一些比较。呃。\n",
            "[18:39.000 --> 18:42.000] 比较比较大的工作吧。我觉得这个也是有前景的。\n",
            "[18:44.000 --> 18:47.000] 明白明了。其实国内现在就是在做。\n",
            "[18:47.000 --> 18:50.000] 这些是卫健委就把这个数据中心放在清华。\n",
            "[18:50.000 --> 18:53.000] 然后。呃。现在好像他们是初步\n",
            "[18:53.000 --> 18:56.000] 达成。我都想还没最后落定。然后最后落定。\n",
            "[18:56.000 --> 18:59.000] 应该就是全国的。呃。至少。\n",
            "[18:59.000 --> 19:02.000] 应该是大部分的医院的数据。可能\n",
            "[19:02.000 --> 19:05.000] 就是脱敏之后。所有的都脱敏。然后标准化的\n",
            "[19:05.000 --> 19:08.000] 可能他的由头是要做各个医院的技术考核。\n",
            "[19:08.000 --> 19:11.000] 然后就把医院的这些数据都拿到。然后清华\n",
            "[19:11.000 --> 19:14.000] 就能来用这些数据做分析。\n",
            "[19:15.000 --> 19:18.000] 嗯。挺有意思。\n",
            "[19:18.000 --> 19:21.000] 感觉明杨就这个就这个技术我们感觉\n",
            "[19:21.000 --> 19:24.000] 已经聊的差不多。然后我感觉我们的逻辑\n",
            "[19:24.000 --> 19:27.000] 是不是从这开始会从。因为有文件还吗。\n",
            "[19:27.000 --> 19:30.000] 我们应该是从文章聊起。嗯。\n",
            "[19:30.000 --> 19:33.000] 从文章聊起然后再再接着这个刚刚的这些问题。\n",
            "[19:33.000 --> 19:36.000] 关于最后的总结可能我也得写点文字。然后或者明杨\n",
            "[19:36.000 --> 19:39.000] 明杨来总结。比如\n",
            "[19:39.000 --> 19:42.000] 明杨用两句话来总结你的看法或者是之类的。\n",
            "[19:42.000 --> 19:45.000] 感觉也就。可以了。\n",
            "[19:45.000 --> 19:48.000] 对。\n",
            "[19:48.000 --> 19:51.000] 对。我觉得拆GPT他刚才写的这个\n",
            "[19:51.000 --> 19:54.000] 这个也还挺好的。也可以加到总结里面。\n",
            "[19:54.000 --> 19:57.000] 他怎么写。嗯。对。他就说。\n",
            "[19:58.000 --> 20:01.000] 嗯。我说英文没他中文有的。\n",
            "[20:01.000 --> 20:04.000] 翻译的就是比较字字翻译。对。\n",
            "[20:04.000 --> 20:07.000] 就说这个。\n",
            "[20:07.000 --> 20:10.000] MIMIC是FREELY ACCESSIBLE\n",
            "[20:10.000 --> 20:13.000] LARGE SCALE\n",
            "[20:13.000 --> 20:16.000] DEIDENTIFIED CRITICAL CARE DATABASE。然后他说。\n",
            "[20:16.000 --> 20:19.000] contains detailed clinical\n",
            "[20:19.000 --> 20:22.000] information on patients admitted to\n",
            "[20:22.000 --> 20:25.000] ICUs at Beth Israel Medical\n",
            "[20:25.000 --> 20:28.000] Center in Boston.\n",
            "[20:28.000 --> 20:31.000] 然后他说。\n",
            "[20:31.000 --> 20:34.000] MIMIC\n",
            "[20:34.000 --> 20:37.000] FACILITATE MEDICAL RESEARCH\n",
            "[20:37.000 --> 20:40.000] IMPROVE THE QUALITY OF CARE AND ADVANCE\n",
            "[20:40.000 --> 20:43.000] HEALTH CARE ANALYTICS BY PROVIDING\n",
            "[20:43.000 --> 20:46.000] A RICH DATA SET FOR RESEARCHERS WORLDWIDE。\n",
            "[20:46.000 --> 20:49.000] 我觉得他是先写了一个总结。\n",
            "[20:49.000 --> 20:52.000] 然后他后面又说MIMIC的一些特点。\n",
            "[20:52.000 --> 20:55.000] 特点主要就是DEIDENTIFIED。\n",
            "[20:55.000 --> 20:58.000] 他说他说MIMIC是高解析度。\n",
            "[20:58.000 --> 21:01.000] 但是这个解析度不是说\n",
            "[21:01.000 --> 21:04.000] 图片的分辨率。他可能说的是\n",
            "[21:04.000 --> 21:07.000] 这种对于时间的这样的一个\n",
            "[21:07.000 --> 21:10.000] 分辨率。他可能很多数据他都是有\n",
            "[21:10.000 --> 21:13.000] 很确定的时间点。然后。\n",
            "[21:13.000 --> 21:16.000] 所以说这种time series的\n",
            "[21:16.000 --> 21:19.000] analysis也是一个很重要的点吧。\n",
            "[21:19.000 --> 21:22.000] 然后很多人可以去。\n",
            "[21:22.000 --> 21:25.000] 他就说他感觉一些这个趋势。\n",
            "[21:25.000 --> 21:28.000] 然后他就是说。\n",
            "[21:28.000 --> 21:31.000] 然后还有这个open access。但是其实我\n",
            "[21:31.000 --> 21:34.000] 我个人认为就题外话。也不能说题外话。就是\n",
            "[21:34.000 --> 21:37.000] MIMIC之外。因为MIMIC他其实就是一个数据。\n",
            "[21:37.000 --> 21:40.000] 然后你怎么去利用这些数据啊。\n",
            "[21:40.000 --> 21:43.000] 包括去用任何的研究方法。\n",
            "[21:43.000 --> 21:46.000] 其实都是不被他所限制的。\n",
            "[21:46.000 --> 21:49.000] 都是你可以怎么样都可以。然后MIMIC的数据\n",
            "[21:49.000 --> 21:52.000] 就是。这种数据的分布吧。\n",
            "[21:52.000 --> 21:55.000] 比如说首先大多数的病人都是ICU的病人。\n",
            "[21:55.000 --> 21:58.000] 那么你如果要是去想做一个\n",
            "[21:58.000 --> 22:01.000] 相对。比如说\n",
            "[22:01.000 --> 22:04.000] 不是ICU的人的一些特征。\n",
            "[22:04.000 --> 22:07.000] 他其实就你可能就做不到\n",
            "[22:07.000 --> 22:10.000] 这样的事情。因为比如说。\n",
            "[22:10.000 --> 22:13.000] 二三十岁的人去看病和\n",
            "[22:13.000 --> 22:16.000] 六七十岁的人进ICU的这样的人的\n",
            "[22:16.000 --> 22:19.000] 身体状况是完全不同的。那么你基于\n",
            "[22:19.000 --> 22:22.000] MIMIC去训练的数据。\n",
            "[22:22.000 --> 22:25.000] 大多数情况。他是不能够泛化的。\n",
            "[22:25.000 --> 22:28.000] 虽然MIMIC现在也出到MIMIC4。\n",
            "[22:28.000 --> 22:31.000] 他慢慢的也越来越多的增加。这些\n",
            "[22:31.000 --> 22:34.000] 就是急诊的一些病人。\n",
            "[22:34.000 --> 22:37.000] 然后也可以有一些方式去过滤掉。\n",
            "[22:37.000 --> 22:40.000] 这些比较重症的人。或者说\n",
            "[22:40.000 --> 22:43.000] 年龄比较大的人。但是你过滤掉之后。他的数据就\n",
            "[22:43.000 --> 22:46.000] 有那么多了。还有MIMIC有一个数据的\n",
            "[22:46.000 --> 22:49.000] 特点就是他会有14个\n",
            "[22:49.000 --> 22:52.000] 疾病的标签。\n",
            "[22:52.000 --> 22:55.000] 这14个疾病标签就是Test Expert他们定义的。\n",
            "[22:55.000 --> 22:58.000] 然后有其中一个标签就叫No finding。\n",
            "[22:58.000 --> 23:01.000] 比如说。就是我说这14个标签\n",
            "[23:01.000 --> 23:04.000] 是针对于胸管S光片的。然后这些是\n",
            "[23:04.000 --> 23:07.000] 通过医生们去看。比如说。\n",
            "[23:07.000 --> 23:10.000] 他们就去看这个片子。比如说能\n",
            "[23:10.000 --> 23:13.000] 通过这个片子直接看出。这\n",
            "[23:13.000 --> 23:16.000] 看出13种病吗?如果看不出。他们或者\n",
            "[23:16.000 --> 23:19.000] 觉得不确定。他们就会标一个No finding。\n",
            "[23:19.000 --> 23:22.000] 或者说他们觉得就是很健康。\n",
            "[23:22.000 --> 23:25.000] 要不然是他们看不出来。对。然后\n",
            "[23:25.000 --> 23:28.000] 也可以直接用No finding的数据去专门去\n",
            "[23:28.000 --> 23:31.000] 做。把这些数据当成\n",
            "[23:31.000 --> 23:34.000] 稍微健康一些的人。然后去进行\n",
            "[23:34.000 --> 23:37.000] 一些疾病的检测。或者这样那样的工作。\n",
            "[23:37.000 --> 23:40.000] 对。然后实际上还有一个很大的问题就是\n",
            "[23:40.000 --> 23:43.000] 医院的病人的数据。\n",
            "[23:43.000 --> 23:46.000] 他的。就还是回到刚才的这个\n",
            "[23:46.000 --> 23:49.000] 分布来讲。他的分布一般都是。\n",
            "[23:49.000 --> 23:52.000] 是非常scoot。他是\n",
            "[23:52.000 --> 23:55.000] 根本就不是正太分布。然后很多\n",
            "[23:55.000 --> 23:58.000] 东西。真正在包括\n",
            "[23:58.000 --> 24:01.000] 他的这些。医疗的\n",
            "[24:01.000 --> 24:04.000] 病例上。其实他的\n",
            "[24:04.000 --> 24:07.000] 他真正处理这样的数据是\n",
            "[24:07.000 --> 24:10.000] 很困难的。很messy。\n",
            "[24:10.000 --> 24:13.000] 很多减写。很多医疗上的\n",
            "[24:13.000 --> 24:16.000] 减写。然后很多\n",
            "[24:16.000 --> 24:19.000] 缩写。很多这样那样不完整的\n",
            "[24:19.000 --> 24:22.000] 句子。然后。都会导致\n",
            "[24:22.000 --> 24:25.000] 里面有很多奇异。或者说\n",
            "[24:25.000 --> 24:28.000] 模糊的东西现象。导致你\n",
            "[24:28.000 --> 24:31.000] 可能在这样的病例里。\n",
            "[24:31.000 --> 24:34.000] 不会去检测到\n",
            "[24:34.000 --> 24:37.000] 你想要的东西。然后呢。\n",
            "[24:37.000 --> 24:40.000] 有一些病例甚至是\n",
            "[24:40.000 --> 24:43.000] 比如说存到mimic里面的时候。他会是\n",
            "[24:43.000 --> 24:46.000] 错误的。或者他根本就不是属于这个人的。他有一些\n",
            "[24:46.000 --> 24:49.000] 比如说这个人的标签标错了。有这样的\n",
            "[24:49.000 --> 24:52.000] 问题都是会存在的。所以他的\n",
            "[24:52.000 --> 24:55.000] 精度也是相对会受限。然后\n",
            "[24:55.000 --> 24:58.000] 算法的发展上面\n",
            "[24:58.000 --> 25:01.000] 也是会相对受限一些。\n",
            "[25:01.000 --> 25:04.000] 那作为研究者。其实你是\n",
            "[25:04.000 --> 25:07.000] 造星者。在其中有没有什么。就是\n",
            "[25:07.000 --> 25:10.000] 去做什么事情。然后想来攻克这些\n",
            "[25:10.000 --> 25:13.000] 挑战呢?因为其实去攻克\n",
            "[25:13.000 --> 25:16.000] 这些挑战。大多数的还是在\n",
            "[25:16.000 --> 25:19.000] 管理方面了。或者说在一些\n",
            "[25:19.000 --> 25:22.000] 其实理论上来讲。越来越多的mimic\n",
            "[25:22.000 --> 25:25.000] 越好。假如说今天\n",
            "[25:25.000 --> 25:28.000] 只有现如今只有Beth Israel提供了\n",
            "[25:28.000 --> 25:31.000] 这样的数据集。那么明天\n",
            "[25:31.000 --> 25:34.000] 波士顿其他的医院如果说他们也同意\n",
            "[25:34.000 --> 25:37.000] 做一个这样的数据呢?\n",
            "[25:37.000 --> 25:40.000] 不单是波士顿地区。比如说\n",
            "[25:40.000 --> 25:43.000] 还有一个原因就是比如说有特定的\n",
            "[25:43.000 --> 25:46.000] 少数族裔或者说一些group\n",
            "[25:46.000 --> 25:49.000] 他们会愿意去一个医院。或者说\n",
            "[25:49.000 --> 25:52.000] 只有一些比较有钱的人愿意去一个医院。\n",
            "[25:52.000 --> 25:55.000] 但是他们的身份的健康状况也都是完全不同。所以这种\n",
            "[25:55.000 --> 25:58.000] 泛化的角度来讲。你的\n",
            "[25:58.000 --> 26:01.000] 数据库越多元当然是越好。\n",
            "[26:01.000 --> 26:04.000] 目前美国就算是全世界可能\n",
            "[26:04.000 --> 26:07.000] 也都是很少有mimic这样的数据集。假如说\n",
            "[26:07.000 --> 26:10.000] 之后不仅是在美国。比如说在洛杉矶\n",
            "[26:10.000 --> 26:13.000] 在西雅图。在南方的\n",
            "[26:13.000 --> 26:16.000] 州的一些医院。然后各种各样的医院都会\n",
            "[26:16.000 --> 26:19.000] 有类似的这种数据集。然后可以\n",
            "[26:19.000 --> 26:22.000] 融合起来的话。那这其实肯定是\n",
            "[26:22.000 --> 26:25.000] 会最大程度上攻克\n",
            "[26:25.000 --> 26:28.000] 这些困难。然后但是这实际上\n",
            "[26:28.000 --> 26:31.000] 最大的问题还是说这种policy\n",
            "[26:31.000 --> 26:34.000] 和management。在这个\n",
            "[26:34.000 --> 26:37.000] 层面。那这层面其实是\n",
            "[26:37.000 --> 26:40.000] 非常非常困难。这么多年其实也\n",
            "[26:40.000 --> 26:43.000] 就mimic一个。所以说\n",
            "[26:43.000 --> 26:46.000] 对。其实目前的现状也不是那么乐观。\n",
            "[26:46.000 --> 26:49.000] 了解。那有没有尝试去\n",
            "[26:49.000 --> 26:52.000] 那就是像现在这个\n",
            "[26:52.000 --> 26:55.000] ofnit chat gbt可能它作为一个开源的\n",
            "[26:55.000 --> 26:58.000] 就是大家能去不断的这个完善\n",
            "[26:58.000 --> 27:01.000] 它。然后它也给大家这个实践的平台吧。\n",
            "[27:01.000 --> 27:04.000] 然后那mimic能不能未来\n",
            "[27:04.000 --> 27:07.000] 尝试这个方式。或者是\n",
            "[27:07.000 --> 27:10.000] 以以尝量的。毕竟我们是主体嘛。\n",
            "[27:10.000 --> 27:13.000] 我们是开发者。然后那未来想\n",
            "[27:13.000 --> 27:16.000] 对。首先ok其实它没有开源。\n",
            "[27:16.000 --> 27:19.000] 它只是把gbt的东西去\n",
            "[27:19.000 --> 27:22.000] 让你不用。它的原代码\n",
            "[27:22.000 --> 27:25.000] 这样那样的东西它都肯定是自己\n",
            "[27:25.000 --> 27:28.000] 自己是有。对。那么mimic这样的东西肯定\n",
            "[27:28.000 --> 27:31.000] 是他们也会接受一些人的意见。但是说\n",
            "[27:31.000 --> 27:34.000] 实在话。现在mimic他们能做的事情\n",
            "[27:34.000 --> 27:37.000] 还是比较有限的。然后\n",
            "[27:37.000 --> 27:40.000] 这些一座二座我们当时\n",
            "[27:40.000 --> 27:43.000] 也都跟他们交流过。然后\n",
            "[27:43.000 --> 27:46.000] 他们大多数时候可能是去跟医院\n",
            "[27:46.000 --> 27:49.000] 打一些交道。或者说把一些数据再去\n",
            "[27:49.000 --> 27:52.000] 进行更多模态的收集。但是实际上\n",
            "[27:52.000 --> 27:55.000] 他们能做的事情也非常有限。然后\n",
            "[27:55.000 --> 27:58.000] 他们肯定是不能就是说迅速的\n",
            "[27:58.000 --> 28:01.000] 扩大多少多少人。然后甚至有\n",
            "[28:01.000 --> 28:04.000] 很多病人的死亡信息。他们也拿不到。\n",
            "[28:04.000 --> 28:07.000] 所以其实在mimic的数据集里可能也只有\n",
            "[28:07.000 --> 28:10.000] 百分之二三十的数据。如果说你的\n",
            "[28:10.000 --> 28:13.000] 任务是想去预测跟病人\n",
            "[28:13.000 --> 28:16.000] survival或者说这种\n",
            "[28:16.000 --> 28:19.000] 这种这种一些疾病的risk有关。\n",
            "[28:19.000 --> 28:22.000] 实际上你是需要死亡的这个信息的。\n",
            "[28:22.000 --> 28:25.000] 病人是存活还是\n",
            "[28:25.000 --> 28:28.000] 还是现在活得挺好的。这些东西\n",
            "[28:28.000 --> 28:31.000] 都是很重要的一些问题。如果说你去\n",
            "[28:31.000 --> 28:34.000] 到这样的一个level\n",
            "[28:34.000 --> 28:37.000] 那实际上它是还是很受限的。\n",
            "[28:37.000 --> 28:40.000] 很多数据集就会变得比较小。\n",
            "[28:43.000 --> 28:46.000] 所以出现这个gap是因为\n",
            "[28:46.000 --> 28:49.000] 算是医院的外部的这个\n",
            "[28:49.000 --> 28:52.000] 信息。对,有很多\n",
            "[28:52.000 --> 28:55.000] 比如说死亡的信息他们是必须要从\n",
            "[28:55.000 --> 28:58.000] 他们是就是不是从\n",
            "[28:58.000 --> 29:01.000] 可能是医院的另一个部门来去保管。\n",
            "[29:01.000 --> 29:04.000] 或者说医院根本就没有去track这些病人。\n",
            "[29:04.000 --> 29:07.000] 他们discharge之后的\n",
            "[29:07.000 --> 29:10.000] 事情了。或者说\n",
            "[29:10.000 --> 29:13.000] 他们也必须要去看这个病人的一些\n",
            "[29:13.000 --> 29:16.000] 马上爆的\n",
            "[29:16.000 --> 29:19.000] 一些level的一些一些一些\n",
            "[29:19.000 --> 29:22.000] 数据。然后可能这些东西都\n",
            "[29:22.000 --> 29:25.000] 很麻烦。然后你再去用deidentify\n",
            "[29:25.000 --> 29:28.000] 的这些病人去追踪\n",
            "[29:28.000 --> 29:31.000] 他们各种各样的事情也非常的麻烦。\n",
            "[29:33.000 --> 29:36.000] 是一个很庞大的工程。然后很多\n",
            "[29:36.000 --> 29:39.000] 东西在我看来就\n",
            "[29:39.000 --> 29:42.000] 其实是挺受限的。然后就算\n",
            "[29:42.000 --> 29:45.000] 是mimic已经是把医院的一个关系\n",
            "[29:45.000 --> 29:48.000] 打通了。实际上它的一些更新也是\n",
            "[29:48.000 --> 29:51.000] 比较慢的。\n",
            "[29:52.000 --> 29:55.000] 了解。那展望未来\n",
            "[29:55.000 --> 29:58.000] 有。\n",
            "[29:58.000 --> 30:01.000] 就是有他们这些这个这个\n",
            "[30:01.000 --> 30:04.000] 做命令的人可能\n",
            "[30:04.000 --> 30:07.000] 有未来。\n",
            "[30:07.000 --> 30:10.000] 因为说句实在话我个人\n",
            "[30:10.000 --> 30:13.000] 是不是特别\n",
            "[30:13.000 --> 30:16.000] 奥芬你应该也听出来我个人\n",
            "[30:16.000 --> 30:19.000] 了解之前我可能是\n",
            "[30:19.000 --> 30:22.000] 比较有希望觉得哇这好酷啊可以用AI去\n",
            "[30:22.000 --> 30:25.000] 直接自动去检测。因为AI本质上就是一种\n",
            "[30:25.000 --> 30:28.000] 自动化。或者说它甚至\n",
            "[30:28.000 --> 30:31.000] 是有一些超越人眼的一些能力。\n",
            "[30:31.000 --> 30:34.000] 比如说目前我在做的\n",
            "[30:34.000 --> 30:37.000] 其实是针对于这种\n",
            "[30:37.000 --> 30:40.000] 病理图像。病理图像其实是那种\n",
            "[30:40.000 --> 30:43.000] 微观的通过显微镜\n",
            "[30:43.000 --> 30:46.000] 这种级别的这样的一种\n",
            "[30:46.000 --> 30:49.000] 图像数据。它其实你去\n",
            "[30:49.000 --> 30:52.000] 放大放大它其实是非常非常大的\n",
            "[30:52.000 --> 30:55.000] 一个图像。那么很多医生\n",
            "[30:55.000 --> 30:58.000] 他们是没有办法看每一个区域的\n",
            "[30:58.000 --> 31:01.000] 他们只能去随机的挑选几个大的区域。然后放大\n",
            "[31:01.000 --> 31:04.000] 然后再看。那么其实通过电脑的话\n",
            "[31:04.000 --> 31:07.000] 它其实是可以全部帮你看一遍。然后全部\n",
            "[31:07.000 --> 31:10.000] 帮你分析提取提取图像的特征\n",
            "[31:10.000 --> 31:13.000] 通过深度学习的方式去做这样的事情。我觉得这个\n",
            "[31:13.000 --> 31:16.000] 是一个很好的方向。\n",
            "[31:16.000 --> 31:19.000] 那么对于Mimic其他的这样一些\n",
            "[31:19.000 --> 31:22.000] 模态和\n",
            "[31:22.000 --> 31:25.000] 工作。其实我认为还是相对比较\n",
            "[31:25.000 --> 31:28.000] 比较困难。然后首先是\n",
            "[31:28.000 --> 31:31.000] 数据级的这种开放程度。再加上\n",
            "[31:31.000 --> 31:34.000] 各个医院。\n",
            "[31:34.000 --> 31:37.000] 所有你跟医院去打交道\n",
            "[31:37.000 --> 31:40.000] 它就是一个很复杂的工作本身。\n",
            "[31:40.000 --> 31:43.000] 通过医院层层打交道\n",
            "[31:43.000 --> 31:46.000] 然后你再去网上去找这种\n",
            "[31:46.000 --> 31:49.000] 有权利的人。然后各种各样的commit都\n",
            "[31:49.000 --> 31:52.000] 需要经过。其实是一些很让人头疼的事情。\n",
            "[31:52.000 --> 31:55.000] 所以我只能说希望未来有越来越多的\n",
            "[31:55.000 --> 31:58.000] 医院和机构能去把他们的\n",
            "[31:58.000 --> 32:01.000] 数据级像Mimic\n",
            "[32:01.000 --> 32:04.000] 一样去整合去公开。\n",
            "[32:04.000 --> 32:07.000] 然后让越来越多的人研究人员\n",
            "[32:07.000 --> 32:10.000] 有越来越多的模态越来越多\n",
            "[32:10.000 --> 32:13.000] 有越来越多量的数据级。那这肯定会推动\n",
            "[32:13.000 --> 32:16.000] 这个领域的发展。还有一个最大的问题\n",
            "[32:16.000 --> 32:19.000] 就是你设计好了这样的\n",
            "[32:19.000 --> 32:22.000] 一个算法。你基于\n",
            "[32:22.000 --> 32:25.000] 的数据。你去训练\n",
            "[32:25.000 --> 32:28.000] 这个算法的数据。非常非常有可能。\n",
            "[32:28.000 --> 32:31.000] 几乎是绝对有绝对绝对的\n",
            "[32:31.000 --> 32:34.000] 会在你真正要去应用的\n",
            "[32:34.000 --> 32:37.000] 场景下。是不一样的。\n",
            "[32:37.000 --> 32:40.000] 还有更大的一个问题是很有可能你当时训练的\n",
            "[32:40.000 --> 32:43.000] Label。你去\n",
            "[32:43.000 --> 32:46.000] 你去Predict这个Label。它可能\n",
            "[32:46.000 --> 32:49.000] 如今的标准也变了。\n",
            "[32:49.000 --> 32:52.000] 所以各种各样的问题。假如说就是去\n",
            "[32:52.000 --> 32:55.000] 衡量糖尿病或者说衡量某种疾病。\n",
            "[32:55.000 --> 32:58.000] 它很有可能在美东\n",
            "[32:58.000 --> 33:01.000] 或者美西或者是好的医院和不好的医院。它的\n",
            "[33:01.000 --> 33:04.000] 称呼甚至都不一样。所以说美国推广了这个\n",
            "[33:04.000 --> 33:07.000] 电子病例ICD code 9011。\n",
            "[33:07.000 --> 33:10.000] 他们甚至有不同的版本。假如说你的\n",
            "[33:10.000 --> 33:13.000] 训练籍是在ICD9这个Label。\n",
            "[33:13.000 --> 33:16.000] 目前可能很多医院已经早就不用ICD9了。\n",
            "[33:16.000 --> 33:19.000] 你这个就很有问题。你就需要重新去\n",
            "[33:19.000 --> 33:22.000] 获取病人的数据再去训练。那么你如果\n",
            "[33:22.000 --> 33:25.000] 想去用ICD11的数据去训练。\n",
            "[33:25.000 --> 33:28.000] 可能Memek还没有到那个地步。\n",
            "[33:28.000 --> 33:31.000] Memek还没有更新。或者说Memek\n",
            "[33:31.000 --> 33:34.000] 更新之后可能你还是没有这样的数据\n",
            "[33:34.000 --> 33:37.000] 所以说在这个领域去\n",
            "[33:37.000 --> 33:40.000] 进行一些机器学习的实际落地应用\n",
            "[33:40.000 --> 33:43.000] 是很困难的。非常困难。尤其是很多\n",
            "[33:43.000 --> 33:46.000] 模态比如说这个地方的人。它是什么样?那个\n",
            "[33:46.000 --> 33:49.000] 地方的人种不一样。尤其是\n",
            "[33:49.000 --> 33:52.000] 在中国还好一点。中国毕竟都是大多数\n",
            "[33:52.000 --> 33:55.000] 都是中国人、黄州人。\n",
            "[33:55.000 --> 33:58.000] 在美国这边就\n",
            "[33:58.000 --> 34:01.000] 非常多元。所以实际上\n",
            "[34:01.000 --> 34:04.000] 现在也有一些案例\n",
            "[34:04.000 --> 34:07.000] 就是有一些疾病的\n",
            "[34:07.000 --> 34:10.000] 这种自动检测是会被肤色\n",
            "[34:10.000 --> 34:13.000] 影响。如果是深肤色的人种\n",
            "[34:13.000 --> 34:16.000] 很有可能他给你的这种\n",
            "[34:17.000 --> 34:20.000] 检测的结果就是非常\n",
            "[34:20.000 --> 34:23.000] bias。非常有偏见性的。\n",
            "[34:23.000 --> 34:26.000] 这些很多东西都是来源于数据的训练的数据。\n",
            "[34:26.000 --> 34:29.000] 很多时候数据也没有那么多代表性。很多这种\n",
            "[34:29.000 --> 34:32.000] 少数族裔的群体呢\n",
            "[34:32.000 --> 34:35.000] 他们的数据量也很少。\n",
            "[34:35.000 --> 34:38.000] 所以说你也很难去进行一个泛化。\n",
            "[34:38.000 --> 34:41.000] 所以在我看来这方面的问题是远远大于\n",
            "[34:41.000 --> 34:44.000] 我对它原来的一些期待和希望。\n",
            "[34:44.000 --> 34:47.000] 对。所以说只能希望以后\n",
            "[34:47.000 --> 34:50.000] 首先有越来越多的模态和数据\n",
            "[34:50.000 --> 34:53.000] 及越来越多的医院。甚至是全世界各种各样的\n",
            "[34:53.000 --> 34:56.000] 东西。能结合起来。\n",
            "[34:56.000 --> 34:59.000] 但是可能国内这方面会做的比较好。\n",
            "[34:59.000 --> 35:02.000] 因为它相对来讲它的权力或者说\n",
            "[35:02.000 --> 35:05.000] 它能集合的一些能力和能量会更大一些。\n",
            "[35:05.000 --> 35:08.000] 相比于美国这边各个地方\n",
            "[35:08.000 --> 35:11.000] 的自治权还是很大的。\n",
            "[35:11.000 --> 35:14.000] 所以说这肯定是一个很好的点。\n",
            "[35:14.000 --> 35:17.000] 再就是AI模型GPT4出来之后\n",
            "[35:17.000 --> 35:20.000] 它其实是对于文本\n",
            "[35:20.000 --> 35:23.000] 甚至是像我之前说的这种\n",
            "[35:23.000 --> 35:26.000] 不规范unstructured data\n",
            "[35:26.000 --> 35:29.000] 它是会有一个极强的理解力的\n",
            "[35:29.000 --> 35:32.000] 比之前所有自然语言处理\n",
            "[35:32.000 --> 35:35.000] 包括在医学方面的自然语言处理都要强大太多。\n",
            "[35:35.000 --> 35:38.000] 所以说我也很期待MIMIC\n",
            "[35:38.000 --> 35:41.000] 就是比如说GPT4它专门在\n",
            "[35:41.000 --> 35:44.000] 医学上去进行一个微调\n",
            "[35:44.000 --> 35:47.000] fine tuning。然后再在MIMIC\n",
            "[35:47.000 --> 35:50.000] 之类的数据或者说各种各样的新的数据上\n",
            "[35:50.000 --> 35:53.000] 去进行一些学习。针对于这个病人的\n",
            "[35:53.000 --> 35:56.000] 电子病例进行一些学习,然后再进行一些精准的推荐。\n",
            "[35:56.000 --> 35:59.000] 我觉得这也是一个很有前景的事情。\n",
            "[35:59.000 --> 36:02.000] 对,基本上就这两点了。\n",
            "[36:02.000 --> 36:05.000] 好,感谢,谢谢文洋。\n",
            "[36:05.000 --> 36:08.000] 其实感觉像是一个\n",
            "[36:08.000 --> 36:11.000] 要买一包走路不断提升这个技术\n",
            "[36:11.000 --> 36:14.000] 以及看看我们到底这个技术\n",
            "[36:14.000 --> 36:17.000] 在这个场景当中会是更有前景像文洋提到的\n",
            "[36:17.000 --> 36:20.000] 或许在中国国内还有很多的\n",
            "[36:20.000 --> 36:23.000] 发展空间,就这个现实情况\n",
            "[36:23.000 --> 36:26.000] 来看。\n",
            "[36:26.000 --> 36:29.000] 因为我感觉挺好的。\n",
            "[36:29.000 --> 36:32.000] 包括我的问题还有最后的总结,可能我也再梳理一下\n",
            "[36:32.000 --> 36:35.000] 然后下次我们就可以真正的合一遍。\n",
            "[36:35.000 --> 36:38.000] 感觉漏到文字,然后这个\n",
            "[36:38.000 --> 36:41.000] 我说的有点多钱,\n",
            "[36:41.000 --> 36:44.000] 我觉得再精简一下就比较好。\n",
            "[36:44.000 --> 36:47.000] 要不然时长咱们也得控制一下。\n",
            "[36:47.000 --> 36:50.000] 然后文章的介绍,\n",
            "[36:50.000 --> 36:53.000] 想放在最开头还是说我们放在中间\n",
            "[36:53.000 --> 36:56.000] 就是说文章给了我们这几点其实\n",
            "[36:56.000 --> 36:59.000] 然后我们再接着看后面的?\n",
            "[36:59.000 --> 37:02.000] 我觉得可以或许可以放到\n",
            "[37:02.000 --> 37:05.000] 当然不是第一句话,比如说浩宏你先说啊,明明\n",
            "[37:05.000 --> 37:08.000] 然后我就开始读,明明真的,我觉得有点无聊。\n",
            "[37:08.000 --> 37:11.000] 设计一个小的开场,然后这个开场我们提一些\n",
            "[37:11.000 --> 37:14.000] 比较有趣的问题,然后再引导美美。\n",
            "[37:14.000 --> 37:17.000] 然后我就说,其实有这样的一个数据库,\n",
            "[37:17.000 --> 37:20.000] 它可以,它是怎么样的,然后它能解决我们之前的\n",
            "[37:20.000 --> 37:23.000] 一些问题,比如说我们之前的一些问题就可以\n",
            "[37:23.000 --> 37:26.000] 提到,病人隐私怎么办?\n",
            "[37:26.000 --> 37:29.000] 或者说,数据量\n",
            "[37:29.000 --> 37:32.000] 多吗?数据量少吗?数量够吗?\n",
            "[37:32.000 --> 37:35.000] 对于这些研究人员的一些\n",
            "[37:35.000 --> 37:38.000] 设计和训练上,就比如说可以涵盖\n",
            "[37:38.000 --> 37:41.000] 这么几个小的问题,然后我就会说,那其实\n",
            "[37:41.000 --> 37:44.000] 这些问题都是非常非常重要,非常\n",
            "[37:44.000 --> 37:47.000] 至关重要的问题,那么实际上\n",
            "[37:47.000 --> 37:50.000] 在每个医院去公开这样的数据集\n",
            "[37:50.000 --> 37:53.000] 或者说决定去做这样的一个数据集\n",
            "[37:53.000 --> 37:56.000] 来去进行一些数字化的分析和创新呢,\n",
            "[37:56.000 --> 37:59.000] 实际上他们都需要了解这些数据,\n",
            "[37:59.000 --> 38:02.000] 了解这样一些\n",
            "[38:02.000 --> 38:05.000] 处理的方式,那么MIMIC其实它在很多方面\n",
            "[38:05.000 --> 38:08.000] 都是一个很成功的案例,很成功的范例,然后\n",
            "[38:08.000 --> 38:11.000] 目前也是,基本上是\n",
            "[38:11.000 --> 38:14.000] 独一档能给全世界的\n",
            "[38:14.000 --> 38:17.000] 所有的研究人员的一些\n",
            "[38:17.000 --> 38:20.000] 一个研究的渠道,而且是\n",
            "[38:20.000 --> 38:23.000] 很容易的去进行这个\n",
            "[38:23.000 --> 38:26.000] MIMIC的获取和在上面进行一些算法的开发。\n",
            "[38:26.000 --> 38:29.000] 然后可以,然后再进入MIMIC\n",
            "[38:29.000 --> 38:32.000] 具体是怎么样,可以这么说。\n",
            "[38:32.000 --> 38:35.000] 那最开始提到的故事,怎么讲\n",
            "[38:35.000 --> 38:38.000] 就我这个视角我想到的就是\n",
            "[38:38.000 --> 38:41.000] 一些现实的问题,就是现在大家在做\n",
            "[38:41.000 --> 38:44.000] 就是两个国家都想做这个数据\n",
            "[38:44.000 --> 38:47.000] 或者至少从一端\n",
            "[38:47.000 --> 38:50.000] 就是既然医院或者医疗集团在管理\n",
            "[38:50.000 --> 38:53.000] 这些数据,大家都想尽可能的发掘好,特别现在\n",
            "[38:53.000 --> 38:56.000] 国内有很多的现实条件是\n",
            "[38:56.000 --> 38:59.000] 它能够联动起来,但是就是需要同步考量\n",
            "[38:59.000 --> 39:02.000] 放在隐私这个数据的量\n",
            "[39:02.000 --> 39:05.000] 可能包括质量和数量,然后\n",
            "[39:05.000 --> 39:08.000] 证实最后的效益,那到底怎么办\n",
            "[39:08.000 --> 39:11.000] 然后相对上,但是我感觉好像不太够生动\n",
            "[39:11.000 --> 39:12.000] 就还是挺\n",
            "[39:13.000 --> 39:16.000] 我觉得要不就可以提几个很小的问题\n",
            "[39:16.000 --> 39:18.000] 比如说,啊\n",
            "[39:18.000 --> 39:21.000] 好朋友你问,你说明阳这个\n",
            "[39:21.000 --> 39:24.000] 现在CHAT GPT这么火\n",
            "[39:24.000 --> 39:27.000] AI这么火,那么AI有没有被\n",
            "[39:27.000 --> 39:30.000] 投入到医疗上面呢\n",
            "[39:30.000 --> 39:33.000] 或者说这种Health Care方面呢,医学方面呢\n",
            "[39:33.000 --> 39:36.000] 然后我就会说,啊现在是有\n",
            "[39:36.000 --> 39:39.000] 是这个怎么怎么样\n",
            "[39:39.000 --> 39:42.000] 然后你说,啊那他们是在哪些方面\n",
            "[39:42.000 --> 39:45.000] 是什么数据,数据集上去训练呢\n",
            "[39:45.000 --> 39:48.000] 他们,那病人的\n",
            "[39:48.000 --> 39:51.000] 去进行训练,肯定是要用病人的数据\n",
            "[39:51.000 --> 39:54.000] 那么病人的数据是怎么样\n",
            "[39:54.000 --> 39:57.000] 保持保证隐私呢,然后我就会说介绍\n",
            "[39:57.000 --> 40:00.000] 一些隐私的问题,啊隐私道德规范\n",
            "[40:00.000 --> 40:03.000] 的一些问题,然后引到deidentification\n",
            "[40:03.000 --> 40:06.000] 然后我就说介绍一下这种可能\n",
            "[40:06.000 --> 40:09.000] 世界上比较大的一个集成性的\n",
            "[40:09.000 --> 40:12.000] 数据,数据医学数据库,那就是MIMIC,然后\n",
            "[40:12.000 --> 40:15.000] 我再会具体说一下MIMIC是怎么样\n",
            "[40:15.000 --> 40:17.000] 然后在哪个医院的,然后\n",
            "[40:18.000 --> 40:20.000] 到后面我们就还可以引到\n",
            "[40:21.000 --> 40:24.000] 我觉得可以到后面去再讲一些这方面\n",
            "[40:24.000 --> 40:27.000] 的见知,对,对,前面先讲一些\n",
            "[40:27.000 --> 40:30.000] 好的地方和一些成功的地方\n",
            "[40:30.000 --> 40:33.000] 或者说成功的一些算法和\n",
            "[40:33.000 --> 40:36.000] 研究的场景,对,其实也就是那篇文章\n",
            "[40:36.000 --> 40:39.000] 提到的一些,嗯,那篇文章其实\n",
            "[40:39.000 --> 40:42.000] 还没有提到太多研究场景,因为他可能\n",
            "[40:42.000 --> 40:45.000] 只propose一点,但是实际上对我个人\n",
            "[40:45.000 --> 40:48.000] 也是知道一些,然后对,XGP感觉\n",
            "[40:48.000 --> 40:51.000] 他写的一些也是挺好,也是比较对的\n",
            "[40:51.000 --> 40:54.000] 对,可以再用他写的那方面,嗯,那\n",
            "[40:54.000 --> 40:57.000] 那个文章就算是前面的小小的一个引入,然后我们\n",
            "[40:57.000 --> 41:00.000] 到时候poll出来的时候,那个文章也就\n",
            "[41:00.000 --> 41:03.000] 作为其中的一个小部分,我们再贴\n",
            "[41:03.000 --> 41:06.000] 其他的已经有的图像\n",
            "[41:08.000 --> 41:11.000] 然后我再次回顾一下,因为我在MIT\n",
            "[41:11.000 --> 41:14.000] 上了一些课就是,嗯\n",
            "[41:14.000 --> 41:17.000] Math and Learning for Healthcare,它是一个很大的课,很多节\n",
            "[41:17.000 --> 41:21.000] 课嘛,它其实是包含了很多东西,然后\n",
            "[41:22.000 --> 41:25.000] 就是上一节课,其实我们还在讲这个\n",
            "[41:25.000 --> 41:28.000] Privacy和Confidentiality\n",
            "[41:28.000 --> 41:31.000] 对,然后Deidentification\n",
            "[41:31.000 --> 41:34.000] 就是一个很重要的东西,然后甚至说ChatGPT\n",
            "[41:34.000 --> 41:37.000] 你都有办法\n",
            "[41:37.000 --> 41:40.000] 去让他,呃\n",
            "[41:40.000 --> 41:43.000] 就是去问他一些病人的信息,然后很有可能\n",
            "[41:43.000 --> 41:46.000] ChatGPT就在其中的一个\n",
            "[41:46.000 --> 41:49.000] 网站上,GitHub上读到过一个人\n",
            "[41:49.000 --> 41:52.000] 的一个代码,或者说他把这个\n",
            "[41:53.000 --> 41:56.000] 一个病人的病例,这个打印出来了\n",
            "[41:56.000 --> 41:59.000] 啊,print出来了,然后放到那个\n",
            "[41:59.000 --> 42:02.000] 一个那个编程的notebook上,然后\n",
            "[42:02.000 --> 42:05.000] 这当然是违反了MIMIC的这个\n",
            "[42:05.000 --> 42:08.000] 因为MIMIC是不会让你去\n",
            "[42:08.000 --> 42:11.000] 去把这些病人的信息去\n",
            "[42:11.000 --> 42:14.000] 放到你开源的网站上,然后\n",
            "[42:14.000 --> 42:17.000] 那很有可能ChatGPT就读到过,然后\n",
            "[42:17.000 --> 42:18.000] 所以说\n",
            "[42:18.000 --> 42:21.000] 其实他是知道这第一个病人的信息的\n",
            "[42:21.000 --> 42:24.000] 但是因为可能是之前那个人\n",
            "[42:24.000 --> 42:27.000] 呃,就是不守规矩的那个人,他其实\n",
            "[42:27.000 --> 42:30.000] 是可能只展示了\n",
            "[42:30.000 --> 42:33.000] 第一个病人,所以说ChatGPT其实好像\n",
            "[42:33.000 --> 42:36.000] 并不知道后面哪些病人,对,就是他们是\n",
            "[42:36.000 --> 42:39.000] 之前有一篇paper,也是我们这个课的\n",
            "[42:39.000 --> 42:42.000] 一个助教,他们组里去做的,就是说\n",
            "[42:42.000 --> 42:45.000] 去查看ChatGPT是不是知道\n",
            "[42:45.000 --> 42:48.000] MIMIC的一些数据,实际还是知道一些的\n",
            "[42:48.000 --> 42:51.000] 所以说这些这些privacy的东西\n",
            "[42:51.000 --> 42:54.000] 其实还是一个,挺有意思的东西\n",
            "[42:54.000 --> 42:55.000] 对\n",
            "[42:56.000 --> 42:59.000] 挺有意思的,好呀,我感觉对\n",
            "[42:59.000 --> 43:02.000] 我们的内容就差不多了,可能更多就是\n",
            "[43:02.000 --> 43:05.000] 梳理,然后让他有意思一点\n",
            "[43:05.000 --> 43:08.000] 然后最后的总结呢,我觉得最开始的开场\n",
            "[43:08.000 --> 43:11.000] 最开始的开场这个很好,然后最后的总结\n",
            "[43:11.000 --> 43:12.000] 我在想\n",
            "[43:13.000 --> 43:16.000] 是回到国内吗,因为你说到美国\n",
            "[43:16.000 --> 43:19.000] 有些挑战,然后可能很难\n",
            "[43:19.000 --> 43:22.000] 美国可能,你肯定要国内的\n",
            "[43:22.000 --> 43:25.000] 我有点观点太强了,这个就知道了\n",
            "[43:25.000 --> 43:28.000] 这个我就还是说一些相当客观的东西\n",
            "[43:28.000 --> 43:31.000] 我觉得就是首先,那我就直接说\n",
            "[43:31.000 --> 43:34.000] 数据阅读就好嘛,希望就是\n",
            "[43:34.000 --> 43:37.000] 各个医院,他们能在\n",
            "[43:37.000 --> 43:40.000] deidentification这个工作上能达成一些一致\n",
            "[43:40.000 --> 43:43.000] 或者说有这样的人员和组织\n",
            "[43:43.000 --> 43:46.000] 去推动这样一个事情\n",
            "[43:46.000 --> 43:48.000] 让他们证明自己的\n",
            "[43:49.000 --> 43:52.000] 类似MIMIC这样的deidentification的过程是\n",
            "[43:52.000 --> 43:55.000] 是合适的,然后也有这样的一个数据的\n",
            "[43:55.000 --> 43:56.000] 组织呢\n",
            "[43:57.000 --> 44:00.000] 专门去推动这件事情,并且是实践\n",
            "[44:00.000 --> 44:03.000] 去各个医院,然后比如说在医院\n",
            "[44:03.000 --> 44:04.000] 就是\n",
            "[44:04.000 --> 44:07.000] 在医院工作,然后\n",
            "[44:07.000 --> 44:10.000] 把这些数据融合起来,然后再像MIMIC这样\n",
            "[44:10.000 --> 44:13.000] 去维护,维持,进行一些\n",
            "[44:13.000 --> 44:16.000] 更新,对,希望可能\n",
            "[44:16.000 --> 44:19.000] 比如说国家层面,假如说有这样的一个组织\n",
            "[44:19.000 --> 44:22.000] 我觉得是很好的,对,我觉得这个倒是\n",
            "[44:22.000 --> 44:25.000] 可以说,我就不会说什么美国怎么样\n",
            "[44:25.000 --> 44:27.000] 中国怎么样,对\n",
            "[44:28.000 --> 44:31.000] 挺好的,然后国家层面两环,一个是最高的\n",
            "[44:31.000 --> 44:34.000] 就是大家先推这个,先有经验的\n",
            "[44:34.000 --> 44:36.000] 大家可能慢慢慢慢的\n",
            "[44:36.000 --> 44:39.000] 在周一周的,就如果大家愿意\n",
            "[44:39.000 --> 44:42.000] 可以慢慢的尝试和组织,或者是国家\n",
            "[44:42.000 --> 44:45.000] 的专门的一个,美国不知道有没有数据\n",
            "[44:45.000 --> 44:48.000] 或者是类似的这种管理性,先就通过\n",
            "[44:48.000 --> 44:49.000] 通过\n",
            "[44:50.000 --> 44:52.000] 可以,咱们就客观来调\n",
            "[44:53.000 --> 44:56.000] 对,然后对,我后面还可以再加\n",
            "[44:56.000 --> 44:59.000] 一些就是假如说算法真的\n",
            "[44:59.000 --> 45:02.000] 推出来了,那下一步其实最头顶的\n",
            "[45:02.000 --> 45:04.000] 就是FDA的各种检查\n",
            "[45:04.000 --> 45:08.000] 就是有一个,我们那前两天MIT还有\n",
            "[45:08.000 --> 45:11.000] 波士顿大学的法学院的\n",
            "[45:11.000 --> 45:14.000] 一个组,专门就是去研究FDA的\n",
            "[45:14.000 --> 45:16.000] 政策和法条的\n",
            "[45:16.000 --> 45:19.000] 还有他们什么样的,就是他们的一些\n",
            "[45:19.000 --> 45:22.000] 怎么说,standard,一些标准\n",
            "[45:22.000 --> 45:24.000] 比如说\n",
            "[45:24.000 --> 45:27.000] 我记得最清楚的,就是任何用图像\n",
            "[45:27.000 --> 45:30.000] 处理图像的处局,都要\n",
            "[45:31.000 --> 45:34.000] 什么说,就FDA其实它是分为,就是有一种\n",
            "[45:34.000 --> 45:35.000] 可以简单的\n",
            "[45:35.000 --> 45:38.000] 用白话来讲,就是有一种你要受到\n",
            "[45:38.000 --> 45:39.000] 它的最强的监管\n",
            "[45:40.000 --> 45:43.000] 有一种就是不太需要,所以说很多人\n",
            "[45:43.000 --> 45:46.000] 他们就是在非常积极的想去把他们的\n",
            "[45:46.000 --> 45:49.000] 产品变得不太受FDA的一些监管\n",
            "[45:49.000 --> 45:51.000] 那这个东西就是\n",
            "[45:51.000 --> 45:54.000] 我目前知道比较确切的,假如说你的\n",
            "[45:54.000 --> 45:57.000] 产品涉及到图像,那这个绝对的\n",
            "[45:57.000 --> 46:00.000] 是绝对会受到监管的,比如说\n",
            "[46:00.000 --> 46:03.000] 一个很简单的案例,就比如说我手上长了个枕子\n",
            "[46:03.000 --> 46:06.000] 或者长了个物子,或者说一个斑\n",
            "[46:06.000 --> 46:07.000] 我想知道它怎么了\n",
            "[46:07.000 --> 46:11.000] 那其实很简单的一个用场,就是咱们现在有手机\n",
            "[46:11.000 --> 46:14.000] 咱们不拍X光片这种东西,你可能要在医院\n",
            "[46:14.000 --> 46:16.000] 才有,但是\n",
            "[46:16.000 --> 46:19.000] 你像如果人人都可以拿手机去拍\n",
            "[46:19.000 --> 46:23.000] 自己的照片,然后传到一个APP上\n",
            "[46:23.000 --> 46:26.000] 然后这个APP就告诉你,你这是什么病\n",
            "[46:26.000 --> 46:29.000] 什么疹子,有没有需要去就医这样那样的\n",
            "[46:29.000 --> 46:32.000] 有几个,它还会分几个\n",
            "[46:32.000 --> 46:35.000] 级别的诊断,假如说\n",
            "[46:35.000 --> 46:38.000] 它直接就告诉你这是什么病,那这个是很严重的\n",
            "[46:38.000 --> 46:41.000] FDA一定要去管你\n",
            "[46:41.000 --> 46:44.000] 就是为什么不想让它管,首先它是很贵\n",
            "[46:44.000 --> 46:47.000] 你需要好像有的,就Premarket\n",
            "[46:47.000 --> 46:50.000] 它一个程序,你需要交当\n",
            "[46:50.000 --> 46:53.000] 将近50万美金,只是一个报名费\n",
            "[46:53.000 --> 46:56.000] 还不包含任何的\n",
            "[46:56.000 --> 46:59.000] 就是你只交这个钱之后,FDA会过来查你\n",
            "[46:59.000 --> 47:02.000] 然后它会跟你进行一系列的审查流程\n",
            "[47:02.000 --> 47:05.000] 就这50多万\n",
            "[47:05.000 --> 47:08.000] means nothing,所以说很多公司融资\n",
            "[47:08.000 --> 47:11.000] 最大的一笔钱,比如说融了100万,可能50多万\n",
            "[47:11.000 --> 47:12.000] 就花在这儿\n",
            "[47:12.000 --> 47:15.000] 所以说这方面\n",
            "[47:15.000 --> 47:18.000] 尤其最可能最让这些\n",
            "[47:18.000 --> 47:21.000] 在这方面想创业的小伙伴们头疼的就是\n",
            "[47:21.000 --> 47:24.000] FDA的政策还是一直会\n",
            "[47:24.000 --> 47:27.000] 怎么说呢,更新的,所以说你并不知道\n",
            "[47:27.000 --> 47:30.000] 你现在被通过了\n",
            "[47:30.000 --> 47:33.000] 有一天之后有没有可能它还会再审查你,审查还好\n",
            "[47:33.000 --> 47:36.000] 万一又不过了,那你就可能要重新设计你\n",
            "[47:36.000 --> 47:39.000] 所有的产品,你的\n",
            "[47:39.000 --> 47:42.000] 流水线,你的这种\n",
            "[47:42.000 --> 47:45.000] 各种各样的cash flow可能都会受到影响\n",
            "[47:45.000 --> 47:48.000] 所以我个人还是认为在这方面\n",
            "[47:48.000 --> 47:51.000] 你去直接进行一些\n",
            "[47:51.000 --> 47:54.000] diagnosis方面的研究\n",
            "[47:54.000 --> 47:57.000] 还是比较困难的,所以说\n",
            "[47:57.000 --> 48:00.000] 我个人还是觉得去做一些,比如说辅助类的系统\n",
            "[48:00.000 --> 48:03.000] 相对会容易一些\n",
            "[48:03.000 --> 48:06.000] 然后相对可实施可实践一些\n",
            "[48:06.000 --> 48:07.000] 然后\n",
            "[48:07.000 --> 48:10.000] 并且是如果说\n",
            "[48:10.000 --> 48:13.000] 能只在一个医院的,或者说在几家医院的\n",
            "[48:13.000 --> 48:16.000] 层面上去推动,而不是面向大众\n",
            "[48:16.000 --> 48:19.000] 那这个相对而言,它也会\n",
            "[48:19.000 --> 48:22.000] 不太受到FDA的检管\n",
            "[48:25.000 --> 48:28.000] 对,这方面也可以提一下,可以放到中间\n",
            "[48:28.000 --> 48:31.000] 或者中后面\n",
            "[48:35.000 --> 48:38.000] 针对这个,像明杨提的问题应该是说\n",
            "[48:38.000 --> 48:41.000] 比如说\n",
            "[48:41.000 --> 48:44.000] 比如说一个产品\n",
            "[48:45.000 --> 48:48.000] 产品研发出来之后\n",
            "[48:48.000 --> 48:51.000] 比如说基于Mimic,研发\n",
            "[48:51.000 --> 48:54.000] 还不错的一个产品,那怎么样去推动\n",
            "[48:54.000 --> 48:57.000] 怎么样去勾递监管\n",
            "[48:57.000 --> 49:00.000] 然后我就会简单提一下\n",
            "[49:00.000 --> 49:03.000] 我比较确定的一些政策类的东西\n",
            "[49:03.000 --> 49:06.000] 或者说一个现状\n",
            "[49:06.000 --> 49:09.000] 好呀,我一会儿我就把问题\n",
            "[49:09.000 --> 49:12.000] 就跟上次一样,做一个演绎一样\n",
            "[49:12.000 --> 49:15.000] 然后做中的时候再碰一下\n",
            "[49:15.000 --> 49:18.000] 然后下次这些钱可能就能\n",
            "[49:18.000 --> 49:21.000] 好的\n",
            "[49:21.000 --> 49:24.000] 先Stop Recording\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/MyDrive/whisper openAI/GMT20230417-004325_Recording.srt**"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # **Run the model** 🚀\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** ⚙️\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"Chinese\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "output_format = 'srt' #@param ['txt', 'vtt', 'srt', 'tsv', 'json', 'all']\n",
        "#@markdown > Type of file to generate to record the transcription.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <br/>\n",
        "\n",
        "#@markdown ### **Optional: Fine tunning** \n",
        "#@markdown ---\n",
        "temperature = 0.15 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to use for sampling.\n",
        "#@markdown ---\n",
        "temperature_increment_on_fallback = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to increase when falling back when the decoding fails to meet either of the thresholds below.\n",
        "#@markdown ---\n",
        "best_of = 5 #@param {type:\"integer\"}\n",
        "#@markdown > Number of candidates when sampling with non-zero temperature.\n",
        "#@markdown ---\n",
        "beam_size = 8 #@param {type:\"integer\"}\n",
        "#@markdown > Number of beams in beam search, only applicable when temperature is zero.\n",
        "#@markdown ---\n",
        "patience = 1.0 #@param {type:\"number\"}\n",
        "#@markdown > Optional patience value to use in beam decoding, as in [*Beam Decoding with Controlled Patience*](https://arxiv.org/abs/2204.05424), the default (1.0) is equivalent to conventional beam search.\n",
        "#@markdown ---\n",
        "length_penalty = -0.05 #@param {type:\"slider\", min:-0.05, max:1, step:0.05}\n",
        "#@markdown > Optional token length penalty coefficient (alpha) as in [*Google's Neural Machine Translation System*](https://arxiv.org/abs/1609.08144), set to negative value to uses simple length normalization.\n",
        "#@markdown ---\n",
        "suppress_tokens = \"-1\" #@param {type:\"string\"}\n",
        "#@markdown > Comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations.\n",
        "#@markdown ---\n",
        "initial_prompt = \"\" #@param {type:\"string\"}\n",
        "#@markdown > Optional text to provide as a prompt for the first window.\n",
        "#@markdown ---\n",
        "condition_on_previous_text = True #@param {type:\"boolean\"}\n",
        "#@markdown > if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop.\n",
        "#@markdown ---\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "#@markdown > whether to perform inference in fp16.\n",
        "#@markdown ---\n",
        "compression_ratio_threshold = 2.4 #@param {type:\"number\"}\n",
        "#@markdown > If the gzip compression ratio is higher than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "logprob_threshold = -1.0 #@param {type:\"number\"}\n",
        "#@markdown > If the average log probability is lower than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "no_speech_threshold = 0.6 #@param {type:\"slider\", min:-0.0, max:1, step:0.05}\n",
        "#@markdown > If the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "args = dict(\n",
        "    language = (None if language == \"Auto detection\" else language),\n",
        "    verbose = verbose_lut[verbose],\n",
        "    task = task,\n",
        "    temperature = temperature,\n",
        "    temperature_increment_on_fallback = temperature_increment_on_fallback,\n",
        "    best_of = best_of,\n",
        "    beam_size = beam_size,\n",
        "    patience=patience,\n",
        "    length_penalty=(length_penalty if length_penalty>=0.0 else None),\n",
        "    suppress_tokens=suppress_tokens,\n",
        "    initial_prompt=(None if not initial_prompt else initial_prompt),\n",
        "    condition_on_previous_text=condition_on_previous_text,\n",
        "    fp16=fp16,\n",
        "    compression_ratio_threshold=compression_ratio_threshold,\n",
        "    logprob_threshold=logprob_threshold,\n",
        "    no_speech_threshold=no_speech_threshold\n",
        ")\n",
        "\n",
        "temperature = args.pop(\"temperature\")\n",
        "temperature_increment_on_fallback = args.pop(\"temperature_increment_on_fallback\")\n",
        "if temperature_increment_on_fallback is not None:\n",
        "    temperature = tuple(np.arange(temperature, 1.0 + 1e-6, temperature_increment_on_fallback))\n",
        "else:\n",
        "    temperature = [temperature]\n",
        "\n",
        "if Model.endswith(\".en\") and args[\"language\"] not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{args['language']}'; using English instead.\")\n",
        "    args[\"language\"] = \"en\"\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    display(Markdown(f\"### {video_path_local}\"))\n",
        "\n",
        "    video_transcription = whisper.transcribe(\n",
        "        whisper_model,\n",
        "        str(video_path_local),\n",
        "        temperature=temperature,\n",
        "        **args,\n",
        "    )\n",
        "\n",
        "    # Save output\n",
        "    whisper.utils.get_writer(\n",
        "        output_format=output_format,\n",
        "        output_dir=video_path_local.parent\n",
        "    )(\n",
        "        video_transcription,\n",
        "        str(video_path_local.stem),\n",
        "        {\n",
        "          \"max_line_width\": 47, \n",
        "          \"max_line_count\": 1,\n",
        "          \"highlight_words\": False\n",
        "        }\n",
        "    )\n",
        "    try:\n",
        "        if output_format==\"all\":\n",
        "            for ext in ('txt', 'vtt', 'srt', 'tsv', 'json'):\n",
        "                transcript_file_name = video_path_local.stem + \".\" + ext\n",
        "                shutil.copy(\n",
        "                    video_path_local.parent / transcript_file_name,\n",
        "                    drive_whisper_path / transcript_file_name\n",
        "                )\n",
        "                display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "        else:\n",
        "            transcript_file_name = video_path_local.stem + \".\" + output_format\n",
        "            shutil.copy(\n",
        "                video_path_local.parent / transcript_file_name,\n",
        "                drive_whisper_path / transcript_file_name\n",
        "            )\n",
        "            display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "\n",
        "    except:\n",
        "        display(Markdown(f\"**Transcript file created: {transcript_local_path}**\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ad6n1m4deAHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}