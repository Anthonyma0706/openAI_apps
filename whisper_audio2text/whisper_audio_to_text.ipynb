{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown # **Install libraries** üèóÔ∏è\n",
    "#@markdown This cell will take a little while to download several libraries, including Whisper.\n",
    "\n",
    "#@markdown ---\n",
    "# ! conda create -n whisper python=3.8\n",
    "# ! conda activate whisper\n",
    "# ! pip install git+https://github.com/openai/whisper.git\n",
    "# ! pip install pytube\n",
    "# ! pip3 install torch torchvision torchaudio\n",
    "import sys\n",
    "import warnings\n",
    "import whisper\n",
    "from pathlib import Path\n",
    "import pytube\n",
    "import subprocess\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown, YouTubeVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "print('Using device:', device, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\n",
      "/bin/bash: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown # **Model selection** üß†\n",
    "\n",
    "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
    "\n",
    "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
    "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
    "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
    "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
    "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
    "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
    "#@markdown | large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
    "\n",
    "#@markdown ---\n",
    "Model = 'medium' #@param ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large']\n",
    "#@markdown ---\n",
    "#@markdown **Run this cell again if you change the model.**\n",
    "\n",
    "whisper_model = whisper.load_model(Model)\n",
    "\n",
    "if Model in whisper.available_models():\n",
    "    display(Markdown(\n",
    "        f\"**{Model} model is selected.**\"\n",
    "    ))\n",
    "else:\n",
    "    display(Markdown(\n",
    "        f\"**{Model} model is no longer available.**<br /> Please select one of the following:<br /> - {'<br /> - '.join(whisper.available_models())}\"\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
